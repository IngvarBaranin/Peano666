{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a1915540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from fractions import Fraction\n",
    "from music21 import *\n",
    "import numpy as np\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c14ef025",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"../dataset/combined/chpn_op25_e11.mid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16aa5e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to open a midi file for further manipulation\n",
    "# Params: string path to a midi file\n",
    "def open_midi_file(midi_file_path):\n",
    "    midifile = converter.parse(midi_file_path)\n",
    "    return midifile\n",
    "\n",
    "# Function to open a midi file's sheet variant in MuseScore, requires MuseScore to be installed\n",
    "# PS: If at first it doesn't work, try following http://web.mit.edu/music21/doc/installing/installWindows.html#install-music21\n",
    "# If it still doesn't work, try running the function a second time for the heck of it. Environment variables be crazy.\n",
    "# Params: string path to a midi file\n",
    "def open_midi_file_musescore(midi_file_path):\n",
    "    midi_file = open_midi_file(midi_file_path)\n",
    "    midi_file.show()\n",
    "    \n",
    "# Function to play a midi file\n",
    "# Params: string path to a midi file\n",
    "def play_midi_file(midi_file_path):\n",
    "    midi_file = open_midi_file(midi_file_path)\n",
    "    midi_file.show(\"midi\")\n",
    "\n",
    "# Function to transpose a midi stream to C major if the song was originally in a major key, or A minor if it was in minor\n",
    "# Params: midi stream (midi file opened with open_midi_file())\n",
    "def transpose_midi_key(midi_file):\n",
    "    midi_key = midi_file.analyze('key')\n",
    "    if (midi_key.mode == \"major\"):\n",
    "        get_interval = interval.Interval(k.tonic, pitch.Pitch('C'))\n",
    "    if (midi_key.mode == \"minor\"):\n",
    "        get_interval = interval.Interval(k.tonic, pitch.Pitch('A'))\n",
    "    transposed_midi = midi_file.transpose(get_interval)\n",
    "    return transposed_midi\n",
    "\n",
    "# Function to convert the whole dataset to tokens and save them in a single .txt file\n",
    "# If you're running this for the first time, it will take a while (more than an hour) because music21 converter.parse\n",
    "# is quite slow. Subsequent times are fast, however, as the parser has pickled the midis somewhere.\n",
    "# Params: string path to folder containing midis, string name of the output file \n",
    "def write_midis_to_txt_as_tokens(midi_folder_path, output_file_name, transpose_bool = False):\n",
    "    \n",
    "    def print_progress(progress, number_of_files, number_of_tokens):\n",
    "        clear_output(wait=True)\n",
    "        print(\"{0} / {1} generated. Number of tokens in current midi: {2}\".format(progress, number_of_files, number_of_tokens))\n",
    "    \n",
    "    path = midi_folder_path\n",
    "    filenames = os.listdir(path)\n",
    "\n",
    "    with open(output_file_name, \"w\") as txt:\n",
    "        progress = 1\n",
    "        for filename in filenames:\n",
    "            midi_as_tokens = convert_midi_to_tokens(path + filename, transpose_bool)\n",
    "            print_progress(progress, len(filenames), len(midi_as_tokens))\n",
    "            txt.write(' '.join(midi_as_tokens) + '\\n')\n",
    "            progress += 1\n",
    "\n",
    "# Function to print the list of unique token values from a list of tokens\n",
    "# Params: a list of tokens, string type of token (wait, note, stop_note) \n",
    "def get_unique_tokens(tokens, token_type):\n",
    "    return set([i.split(\":\")[1] for i in tokens if i.startswith(token_type)])\n",
    "    \n",
    "# Function to make sure that a list of tokens contains a stop_note event for every note starting event\n",
    "# Works similarly to adding a note in the tokens to midi conversion function\n",
    "# Params: a list of tokens\n",
    "# Returns true if all notes end properly, false if not\n",
    "def validate_tokens(tokens):\n",
    "    \n",
    "    # Keeps track of the current token\n",
    "    current_token_index = 0\n",
    "    \n",
    "    # Keeps track of notes that aren't stopped, if any\n",
    "    not_stopped_notes = list() \n",
    "    \n",
    "    # The converter ignores BOS and EOS tags\n",
    "    tokens = [token for token in tokens if token not in [\"<EOS>\", \"<BOS>\"]]\n",
    "    \n",
    "    for token in tokens:\n",
    "        token_type = token.split(\":\")[0]\n",
    "        token_value = token.split(\":\")[1]\n",
    "        \n",
    "        if token_type == \"note\":\n",
    "            found_corresponding_end_note = False\n",
    "            note_midi_pitch = token_value\n",
    "            \n",
    "            for following_token in tokens[current_token_index + 1:]:\n",
    "                following_token_type = following_token.split(\":\")[0]\n",
    "                following_token_value = following_token.split(\":\")[1]\n",
    "                    \n",
    "                if following_token_type == \"stop_note\":\n",
    "                    stopped_note_pitch = following_token_value\n",
    "                    if (note_midi_pitch == stopped_note_pitch):\n",
    "                        found_corresponding_end_note = True\n",
    "                        break\n",
    "            \n",
    "            if not found_corresponding_end_note:\n",
    "                not_stopped_notes.append(token)\n",
    "                \n",
    "    return len(not_stopped_notes) == 0, not_stopped_notes\n",
    "    \n",
    "# Function to turn a midi file into text tokens\n",
    "# Params: string path to a midi file, bool whether to transpose all midis or not\n",
    "def convert_midi_to_tokens(midi_file_path, transpose_bool = False):\n",
    "    \n",
    "    # Function to remap velocity to not oversaturate the possible range of velocities\n",
    "    # Completely made up values\n",
    "    def remap_velocity(velocity):\n",
    "        if velocity <= 42:\n",
    "            return 50\n",
    "        if velocity <= 84:\n",
    "            return 70\n",
    "        return 90\n",
    "    \n",
    "    def remap_tempo(tempo):\n",
    "        if tempo <= 40:\n",
    "            return 40\n",
    "        if tempo >= 140:\n",
    "            return 140\n",
    "        return tempo - (tempo % 10)\n",
    "            \n",
    "    def velocity_change_handler(current_velocity, note_velocity, tokens_to_add):\n",
    "        remapped_new_velocity = remap_velocity(note_velocity)\n",
    "        if (current_velocity != remapped_new_velocity):\n",
    "            current_velocity = remapped_new_velocity\n",
    "            tokens_to_add.append(\"velocity:\" + str(remapped_new_velocity))\n",
    "        return tokens_to_add, current_velocity\n",
    "    \n",
    "    def tempo_change_handler(current_tempo, new_tempo, tokens_to_add):\n",
    "        remapped_new_tempo = remap_tempo(new_tempo)\n",
    "        if (current_tempo != remapped_new_tempo):\n",
    "            current_tempo = remapped_new_tempo\n",
    "            tokens_to_add.append(\"tempo:\" + str(remapped_new_tempo))\n",
    "        return tokens_to_add, current_tempo\n",
    "    \n",
    "    midi_file = open_midi_file(midi_file_path)\n",
    "    \n",
    "    if transpose_bool:\n",
    "        midi_file = transpose_midi_key(midi_file)\n",
    "    \n",
    "    # A list to hold tokens\n",
    "    tokens = list()\n",
    "    \n",
    "    # A list to keep track of which note events await a corresponding note off event\n",
    "    notes_to_stop = list()\n",
    "    \n",
    "    # Keeps track of time since start of the midi piece\n",
    "    current_offset = 0\n",
    "    \n",
    "    # Keeps track of velocity (note volume), used to add a velocity token every time this variable value changes\n",
    "    # Theoretically can range from 0 to 127, but the possible range of values will be remapped to keep the final model simple\n",
    "    # Default value of 70 is chosen because the author likes it\n",
    "    current_velocity = 70\n",
    "    \n",
    "    # Keeps track of tempo, used to add a tempo token every time this variable value changes\n",
    "    current_tempo = None\n",
    "    \n",
    "    # Keeps track of the offset of the previously handled midi event\n",
    "    previous_offset = 0.0\n",
    "    offset_changed = False\n",
    "    \n",
    "    # Because we are mushing different streams of MIDI events (e.g. left & right hand parts) into a single stream,\n",
    "    # the tempos and time signatures are duplicated. The encoding, however, only needs to see them once.\n",
    "    # previous_event is used to check if we just saw a tempo/timesig token to know if we should ignore its second occurrence.\n",
    "    previous_event = None\n",
    "    \n",
    "    # Iterate over all midi events, sorted by offset (ascending)\n",
    "    # and handle which tokens will be added to list of tokens\n",
    "    for midi_event in midi_file.flat.elements:\n",
    "        \n",
    "        current_offset = midi_event.offset\n",
    "        \n",
    "        # At the end of the current loop, tokens in this list will be added to the final tokens list\n",
    "        tokens_to_add = list()\n",
    "        \n",
    "        # Check if there are notes that should have ended between the last and current offset (included) \n",
    "        if len(notes_to_stop) != 0:\n",
    "            for note_to_stop, when_to_stop in [note[:] for note in notes_to_stop]:\n",
    "                if when_to_stop <= current_offset:\n",
    "                    time_since_prev_offset = common.opFrac(when_to_stop - previous_offset)\n",
    "                    if time_since_prev_offset > 0:\n",
    "                        tokens_to_add.append(\"wait:\" + str(time_since_prev_offset))\n",
    "                        previous_offset = when_to_stop\n",
    "                    tokens_to_add.append(\"stop_note:\" + note_to_stop)\n",
    "                    notes_to_stop.remove([note_to_stop, when_to_stop])\n",
    "        \n",
    "        # If the offset has changed by >0, account for it by adding a waiting token\n",
    "        if (current_offset > previous_offset and isinstance(midi_event, (note.Note, chord.Chord))):\n",
    "            offset_changed = True\n",
    "            offset_change = common.opFrac(current_offset - previous_offset)\n",
    "            tokens_to_add.append(\"wait:\" + str(offset_change))\n",
    "        \n",
    "        if isinstance(midi_event, tempo.MetronomeMark) and not isinstance(previous_event, tempo.MetronomeMark):\n",
    "            tempo_value = midi_event.number\n",
    "            tokens_to_add, current_tempo = tempo_change_handler(current_tempo, tempo_value, tokens_to_add)\n",
    "        \n",
    "        # If the current midi event is a note, add a note token along with its midi pitch number\n",
    "        # And remember when the note needs to be stopped\n",
    "        if isinstance(midi_event, note.Note):\n",
    "            midi_pitch = str(midi_event.pitch.midi)\n",
    "            note_velocity = midi_event.volume.velocity\n",
    "            \n",
    "            tokens_to_add, current_velocity = velocity_change_handler(current_velocity, note_velocity, tokens_to_add)\n",
    "            \n",
    "            token_string = \"note:\" + midi_pitch\n",
    "            \n",
    "            note_end_offset = common.opFrac(current_offset + midi_event.duration.quarterLength)\n",
    "            \n",
    "            tokens_to_add.append(token_string)\n",
    "            notes_to_stop.append([midi_pitch, note_end_offset])\n",
    "        \n",
    "        # If the current midi event is a chord, do the same as before for every note in the chord\n",
    "        if isinstance(midi_event, chord.Chord):\n",
    "            for individual_note in midi_event:\n",
    "                midi_pitch = str(individual_note.pitch.midi)\n",
    "                note_velocity = midi_event.volume.velocity\n",
    "                \n",
    "                tokens_to_add, current_velocity = velocity_change_handler(current_velocity, note_velocity, tokens_to_add)\n",
    "                \n",
    "                token_string = \"note:\" + midi_pitch\n",
    "                \n",
    "                note_end_offset = common.opFrac(current_offset + midi_event.duration.quarterLength)\n",
    "\n",
    "                tokens_to_add.append(token_string)\n",
    "                notes_to_stop.append([midi_pitch, note_end_offset])\n",
    "        \n",
    "        tokens.extend(tokens_to_add)\n",
    "        \n",
    "        # I can't for the life of me remember why offset_changed is required, but it makes everything work. Do not touch, lol.\n",
    "        if offset_changed:\n",
    "            offset_changed = False\n",
    "            previous_offset = current_offset\n",
    "        previous_event = midi_event\n",
    "    \n",
    "    # After iterating through all midi events, it is necessary to check for note stopping events one more time,\n",
    "    # since the last midi event could have been a note starting event\n",
    "    tokens_to_add = list()\n",
    "    if len(notes_to_stop) != 0:\n",
    "        for note_to_stop, when_to_stop in [note[:] for note in notes_to_stop]:\n",
    "            time_since_prev_offset = common.opFrac(when_to_stop - previous_offset)\n",
    "            if time_since_prev_offset > 0:\n",
    "                tokens_to_add.append(\"wait:\" + str(time_since_prev_offset))\n",
    "                previous_offset = when_to_stop\n",
    "            tokens_to_add.append(\"stop_note:\" + note_to_stop)\n",
    "            notes_to_stop.remove([note_to_stop, when_to_stop])\n",
    "    tokens.extend(tokens_to_add)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Function to convert list of text tokens to a Music21 midi stream\n",
    "# Params: a list of tokens\n",
    "def convert_tokens_to_midi(tokens):\n",
    "    \n",
    "    # A midi stream that will hold midi events converted from tokens\n",
    "    midi_stream = stream.Stream()\n",
    "    \n",
    "    # Keeps track of the current token\n",
    "    current_token_index = 0\n",
    "    \n",
    "    # Keeps track of offset\n",
    "    current_offset = 0\n",
    "    \n",
    "    # Keeps track of velocity\n",
    "    current_velocity = 70\n",
    "    \n",
    "    # The converter ignores BOS and EOS tags\n",
    "    tokens = [token for token in tokens if token not in [\"<EOS>\", \"<BOS>\"]]\n",
    "    \n",
    "    for token in tokens:\n",
    "        token_type = token.split(\":\")[0]\n",
    "        token_value = token.split(\":\")[1]\n",
    "        \n",
    "        # Time signatures are unnecessary for playback. Commented out.\n",
    "        if token_type == \"timesignature\":\n",
    "            timesignature_value = token_value\n",
    "            midi_stream.append(meter.TimeSignature(timesignature_value))\n",
    "        \n",
    "        if token_type == \"tempo\":\n",
    "            tempo_value = float(token_value)\n",
    "            midi_stream.append(tempo.MetronomeMark(number=tempo_value))\n",
    "            \n",
    "        if token_type == \"velocity\":\n",
    "            velocity_value = float(token_value)\n",
    "            current_velocity = velocity_value\n",
    "        \n",
    "        # Converting a note-starting token to a midi event, we need to know its duration.\n",
    "        # To find the duration, we look at the following tokens until we find a corresponding stop_note token.\n",
    "        # While searching for the stop_note token, we add up the values of intermediate wait tokens, denoting duration.\n",
    "        # We identify the corresponding stop_note by the note's midi pitch number. \n",
    "        if token_type == \"note\":\n",
    "            note_duration = 0\n",
    "            note_midi_pitch = token_value\n",
    "\n",
    "            for following_token in tokens[current_token_index + 1:]:\n",
    "                following_token_type = following_token.split(\":\")[0]\n",
    "                following_token_value = following_token.split(\":\")[1]\n",
    "                \n",
    "                if following_token_type == \"wait\":\n",
    "                    wait_duration = common.opFrac(Fraction(following_token_value))\n",
    "                    note_duration += common.opFrac(wait_duration)\n",
    "                    \n",
    "                if following_token_type == \"stop_note\":\n",
    "                    stopped_note_pitch = following_token_value\n",
    "                    if (note_midi_pitch == stopped_note_pitch):\n",
    "                        new_note = note.Note(int(note_midi_pitch))  \n",
    "                        new_note.quarterLength = note_duration\n",
    "                        new_note.volume.velocity = current_velocity\n",
    "                        midi_stream.insert(current_offset, new_note)\n",
    "                        break\n",
    "\n",
    "        if token_type == \"wait\":\n",
    "            wait_duration = common.opFrac(Fraction(token_value))\n",
    "            current_offset += common.opFrac(wait_duration)\n",
    "\n",
    "        current_token_index += 1\n",
    "\n",
    "    return midi_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9410335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#midi_file = open_midi_file(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "54adce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open_midi_file_musescore(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4204862e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#play_midi_file(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce3b0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validate_tokens(convert_midi_to_tokens(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c6e3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#miditokens = convert_midi_to_tokens(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "91040d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert_tokens_to_midi(miditokens).show(\"midi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4f7494",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_unique_tokens(miditokens, \"wait\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "a1259890",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write_midis_to_txt_as_tokens(\"../dataset/combined/\", \"./training_data.txt\", False)\n",
    "#write_midis_to_txt_as_tokens(\"../dataset/combined/\", \"./training_data_transposed.txt\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f28d6d",
   "metadata": {},
   "source": [
    "### Encoding debugging 💉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "5cbdca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#miditokens = convert_midi_to_tokens(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "6b652019",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original = open_midi_file(test_path)\n",
    "#new = convert_tokens_to_midi(miditokens)\n",
    "#new.show(\"midi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c6d77f",
   "metadata": {},
   "source": [
    "Comparing the contents of the original MIDI and the one that's been MIDI -> token -> MIDI converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "16467c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#listofnotes = list()\n",
    "#listofnotes2 = list()\n",
    "#\n",
    "#for i in original.flat.elements:\n",
    "#    if isinstance(i, note.Note):\n",
    "#        duration = str(float(round(i.duration.quarterLength, 3)))\n",
    "#        offset = str(float(round(i.offset, 3)))\n",
    "#        pitch = str(i.pitch)\n",
    "#        ischord = \"False\"\n",
    "#        \n",
    "#        listofnotes.append(\" \".join([offset, duration, pitch]))\n",
    "#    \n",
    "#    if isinstance(i, chord.Chord):\n",
    "#        duration = str(float(round(i.duration.quarterLength, 3)))\n",
    "#        offset = str(float(round(i.offset, 3)))\n",
    "#        ischord = \"True\"\n",
    "#        \n",
    "#        for indnote in i:\n",
    "#            pitch = str(indnote.pitch)\n",
    "#            listofnotes.append(\" \".join([offset, duration, pitch]))\n",
    "#        \n",
    "#for i in new.flat.elements:\n",
    "#    if isinstance(i, note.Note):\n",
    "#        duration = str(float(round(i.duration.quarterLength, 3)))\n",
    "#        offset = str(float(round(i.offset, 3)))\n",
    "#        pitch = str(i.pitch)\n",
    "#        ischord = \"False\"\n",
    "#        \n",
    "#        listofnotes2.append(\" \".join([offset, duration, pitch]))\n",
    "#        \n",
    "#for i, j in zip(listofnotes, listofnotes2):\n",
    "#    i_offs = i.split(\" \")[0]\n",
    "#    j_offs = j.split(\" \")[0]\n",
    "#    \n",
    "#    i_dur = i.split(\" \")[1]\n",
    "#    j_dur = j.split(\" \")[1]\n",
    "#    \n",
    "#    i_note = i.split(\" \")[2]\n",
    "#    j_note = j.split(\" \")[2]\n",
    "#    \n",
    "#    print(i_offs, j_offs, \"\\t\", i_dur, j_dur, \"\\t\", i_note, j_note, i == j)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
