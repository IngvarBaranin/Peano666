{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa659fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "music21: Certain music21 functions might need the optional package matplotlib;\n",
      "                  if you run into errors, install it by following the instructions at\n",
      "                  http://mit.edu/music21/doc/installing/installAdditional.html\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "%run midi_utils.ipynb\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c856a2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_loading(i, n_tokens_to_generate, n_unique, stop_at_EOS):\n",
    "    clear_output(wait=True)\n",
    "    if not stop_at_EOS:\n",
    "        print(str(i), \"/\", str(n_tokens_to_generate), \"generated. Unique tokens in sliding seq:\", str(n_unique))\n",
    "        return\n",
    "    print(str(i), \"/ ?\", \"generated. Unique tokens in sliding seq:\", str(n_unique))\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "    \n",
    "# Function to generate music.\n",
    "# Temperature determines how confident the model should be in its predictions. Lower = more confident\n",
    "def generate_music(model, vocab_size, vocabulary, starting_input, n_tokens_to_generate, temperature = 1.0, stop_at_EOS = False):\n",
    "    \n",
    "    # Keeps track of the number of tokens generated so far\n",
    "    i = 0\n",
    "    \n",
    "    # Used as input, where the first input is a bunch of random tokens from the vocabulary \n",
    "    # It's sliding because the predicted token will be constantly appended to the input\n",
    "    # [0, 1, 2] -predict-> [3] \n",
    "    # [1, 2, 3] -predict-> [4]\n",
    "    # [2, 3, 4] and so on\n",
    "    if starting_input == None:\n",
    "        sliding_window = [np.random.randint(159, 160, size=99).tolist()]\n",
    "    else:\n",
    "        sliding_window = [starting_input]\n",
    "    \n",
    "    # Inverse of the vocabulary, because the tokens in integer form need to be converted back to tokens\n",
    "    int_to_token_dict = dict(map(reversed, vocabulary.items()))\n",
    "    \n",
    "    # List that holds the final output. Grows by each prediction.\n",
    "    prediction_output = []\n",
    "    \n",
    "    while True:\n",
    "        # Convert to the same format as the one the model saw during training\n",
    "        prediction_input = to_categorical(sliding_window, num_classes = vocab_size)\n",
    "\n",
    "        # Predict next token depending on the current sequence \n",
    "        prediction = model(prediction_input)[0]\n",
    "        i += 1\n",
    "        \n",
    "        # Get the integer variant of the token\n",
    "        #index = np.argmax(prediction)\n",
    "        index = sample(prediction, temperature)\n",
    "        \n",
    "        # Grab the token variant of the integer and append the resulting token to prediction output\n",
    "        result = int_to_token_dict[index]\n",
    "        prediction_output.append(result)\n",
    "        \n",
    "        # Slide the input 1 int to the right, appending the current prediction and removing one token from the start,\n",
    "        # so the sequence length will stay the same\n",
    "        sliding_window = np.append(sliding_window, index)\n",
    "        sliding_window = [sliding_window[1:len(sliding_window)]]\n",
    "        \n",
    "        # A loading bar for the impatient\n",
    "        print_loading(i, n_tokens_to_generate, len(np.unique(sliding_window)), stop_at_EOS)\n",
    "        \n",
    "        if (stop_at_EOS and result == \"<EOS>\") or (i == n_tokens_to_generate):\n",
    "            break\n",
    "            \n",
    "    return prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88de11e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {token: int(token_int) for token, token_int in json.load(open(\"./dictionary.json\")).items()}\n",
    "model = tf.keras.models.load_model(\"../best_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "98f8ef3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 / 700 generated. Unique tokens in sliding seq: 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv134021'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv134021');\n",
       "                               mp.base64Load('data:audio/midi;base64,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');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generated_tokens = generate_music(model, len(vocabulary), vocabulary, None, 700, 0.7)\n",
    "generated_midi_stream = convert_tokens_to_midi(generated_tokens)\n",
    "generated_midi_stream.show(\"midi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8c79c0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 / 3000 generated. Unique tokens in sliding seq: 32\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 50):\n",
    "    generated_tokens = generate_music(model, len(vocabulary), vocabulary, None, 3000, 0.7)\n",
    "    generated_midi_stream = convert_tokens_to_midi(generated_tokens)\n",
    "    midi_filepath = \"../generated_samples/LSTM_objective\" + str(i) + \".mid\"\n",
    "    generated_midi_stream.write('midi', fp=midi_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bab7f23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, [])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_tokens(generated_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
