{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Evaluation_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcKZ-psd1jJu"
      },
      "source": [
        "# Classifier of Classical Music Midis and Markov Model generated Midis for objective evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnm4JzcJ4Wks"
      },
      "source": [
        "## Setup:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQ01ZHcr4X-F"
      },
      "source": [
        "\n",
        "Importing the MM data from Google Drive:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "BdyqA7id1hZI",
        "outputId": "ea344f1a-fdf8-4f5d-c1ac-0d621627a255"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \"\"\"\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-4996ee3d8d09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    258\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dfs-auth-dance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m           \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMLuQSkP2oTQ"
      },
      "source": [
        "I just copied the MIDI processing functions from midi_utils.ipynb for the time being "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPiujhfZ2oxn"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from fractions import Fraction\n",
        "from music21 import *\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "import os\n",
        "import math\n",
        "\n",
        "\n",
        "def open_midi_file(midi_file_path):\n",
        "    midifile = converter.parse(midi_file_path)\n",
        "    return midifile\n",
        "\n",
        "# Function to open a midi file's sheet variant in MuseScore, requires MuseScore to be installed\n",
        "# PS: If at first it doesn't work, try following http://web.mit.edu/music21/doc/installing/installWindows.html#install-music21\n",
        "# If it still doesn't work, try running the function a second time for the heck of it. Environment variables be crazy.\n",
        "# Params: string path to a midi file\n",
        "def open_midi_file_musescore(midi_file_path):\n",
        "    midi_file = open_midi_file(midi_file_path)\n",
        "    midi_file.show()\n",
        "    \n",
        "# Function to play a midi file\n",
        "# Params: string path to a midi file\n",
        "def play_midi_file(midi_file_path):\n",
        "    midi_file = open_midi_file(midi_file_path)\n",
        "    midi_file.show(\"midi\")\n",
        "\n",
        "# Function to transpose a midi stream to C major if the song was originally in a major key, or A minor if it was in minor\n",
        "# Params: midi stream (midi file opened with open_midi_file())\n",
        "def transpose_midi_key(midi_file):\n",
        "    midi_key = midi_file.analyze('key')\n",
        "    if (midi_key.mode == \"major\"):\n",
        "        get_interval = interval.Interval(k.tonic, pitch.Pitch('C'))\n",
        "    if (midi_key.mode == \"minor\"):\n",
        "        get_interval = interval.Interval(k.tonic, pitch.Pitch('A'))\n",
        "    transposed_midi = midi_file.transpose(get_interval)\n",
        "    return transposed_midi\n",
        "\n",
        "# Function to convert the whole dataset to tokens and save them in a single .txt file\n",
        "# If you're running this for the first time, it will take a while (more than an hour) because music21 converter.parse\n",
        "# is quite slow. Subsequent times are fast, however, as the parser has pickled the midis somewhere.\n",
        "# Params: string path to folder containing midis, string name of the output file \n",
        "def write_midis_to_txt_as_tokens(midi_folder_path, output_file_name, transpose_bool = False):\n",
        "    \n",
        "    def print_progress(progress, number_of_files, number_of_tokens):\n",
        "        clear_output(wait=True)\n",
        "        print(\"{0} / {1} generated. Number of tokens in current midi: {2}\".format(progress, number_of_files, number_of_tokens))\n",
        "    \n",
        "    path = midi_folder_path\n",
        "    filenames = os.listdir(path)\n",
        "\n",
        "    with open(output_file_name, \"w\") as txt:\n",
        "        progress = 1\n",
        "        for filename in filenames:\n",
        "            midi_as_tokens = convert_midi_to_tokens(path + filename, transpose_bool)\n",
        "            print_progress(progress, len(filenames), len(midi_as_tokens))\n",
        "            txt.write(' '.join(midi_as_tokens) + '\\n')\n",
        "            progress += 1\n",
        "\n",
        "# Function to print the list of unique token values from a list of tokens\n",
        "# Params: a list of tokens, string type of token (wait, note, stop_note) \n",
        "def get_unique_tokens(tokens, token_type):\n",
        "    return set([i.split(\":\")[1] for i in tokens if i.startswith(token_type)])\n",
        "\n",
        "# Checks if a value is essentially 0\n",
        "def epsilon(n):\n",
        "    return math.isclose(n, 0, abs_tol = 0.002)\n",
        "\n",
        "def almost_whole(n):\n",
        "    return epsilon(n % 1) or epsilon((n % 1) - 1)\n",
        "    \n",
        "# Function to make sure that a list of tokens contains a stop_note event for every note starting event\n",
        "# Works similarly to adding a note in the tokens to midi conversion function\n",
        "# Params: a list of tokens\n",
        "# Returns true if all notes end properly, false if not\n",
        "def validate_tokens(tokens):\n",
        "    \n",
        "    # Keeps track of the current token\n",
        "    current_token_index = 0\n",
        "    \n",
        "    # Keeps track of notes that aren't stopped, if any\n",
        "    not_stopped_notes = list() \n",
        "    \n",
        "    for token in tokens:\n",
        "        token_type = token.split(\":\")[0]\n",
        "        token_value = token.split(\":\")[1]\n",
        "        \n",
        "        if token_type == \"note\":\n",
        "            found_corresponding_end_note = False\n",
        "            note_midi_pitch = token_value\n",
        "            \n",
        "            for following_token in tokens[current_token_index + 1:]:\n",
        "                following_token_type = following_token.split(\":\")[0]\n",
        "                following_token_value = following_token.split(\":\")[1]\n",
        "                    \n",
        "                if following_token_type == \"stop_note\":\n",
        "                    stopped_note_pitch = following_token_value\n",
        "                    if (note_midi_pitch == stopped_note_pitch):\n",
        "                        found_corresponding_end_note = True\n",
        "                        break\n",
        "            \n",
        "            if not found_corresponding_end_note:\n",
        "                not_stopped_notes.append(token)\n",
        "                \n",
        "    return len(not_stopped_notes) == 0, not_stopped_notes\n",
        "    \n",
        "# Function to turn a midi file into text tokens\n",
        "# Params: string path to a midi file, bool whether to transpose all midis or not\n",
        "def convert_midi_to_tokens(midi_file_path, transpose_bool = False):\n",
        "    \n",
        "    # Function to remap velocity to not oversaturate the possible range of velocities\n",
        "    # Completely made up values\n",
        "    def remap_velocity(velocity):\n",
        "        if velocity <= 42:\n",
        "            return 50\n",
        "        if velocity <= 84:\n",
        "            return 70\n",
        "        return 90\n",
        "    \n",
        "    def remap_tempo(tempo):\n",
        "        if tempo <= 40:\n",
        "            return 40\n",
        "        if tempo >= 140:\n",
        "            return 140\n",
        "        return tempo - (tempo % 10)\n",
        "            \n",
        "    def velocity_change_handler(current_velocity, note_velocity, tokens_to_add):\n",
        "        remapped_new_velocity = remap_velocity(note_velocity)\n",
        "        if (current_velocity != remapped_new_velocity):\n",
        "            current_velocity = remapped_new_velocity\n",
        "            tokens_to_add.append(\"velocity:\" + str(remapped_new_velocity))\n",
        "        return tokens_to_add, current_velocity\n",
        "    \n",
        "    def tempo_change_handler(current_tempo, new_tempo, tokens_to_add):\n",
        "        remapped_new_tempo = remap_tempo(new_tempo)\n",
        "        if (current_tempo != remapped_new_tempo):\n",
        "            current_tempo = remapped_new_tempo\n",
        "            tokens_to_add.append(\"tempo:\" + str(remapped_new_tempo))\n",
        "        return tokens_to_add, current_tempo\n",
        "    \n",
        "    midi_file = open_midi_file(midi_file_path)\n",
        "    \n",
        "    if transpose_bool:\n",
        "        midi_file = transpose_midi_key(midi_file)\n",
        "    \n",
        "    # A list to hold tokens\n",
        "    tokens = list()\n",
        "    \n",
        "    # A list to keep track of which note events await a corresponding note off event\n",
        "    notes_to_stop = list()\n",
        "    \n",
        "    # Keeps track of time since start of the midi piece\n",
        "    current_offset = 0\n",
        "    \n",
        "    # Keeps track of velocity (note volume), used to add a velocity token every time this variable value changes\n",
        "    # Theoretically can range from 0 to 127, but the possible range of values will be remapped to keep the final model simple\n",
        "    # Default value of 70 is chosen because the author likes it\n",
        "    current_velocity = 70\n",
        "    \n",
        "    # Keeps track of tempo, used to add a tempo token every time this variable value changes\n",
        "    current_tempo = None\n",
        "    \n",
        "    # Keeps track of the offset of the previously handled midi event\n",
        "    previous_offset = 0.0\n",
        "    offset_changed = False\n",
        "    \n",
        "    # Because we are mushing different streams of MIDI events (e.g. left & right hand parts) into a single stream,\n",
        "    # the tempos and time signatures are duplicated. The encoding, however, only needs to see them once.\n",
        "    # previous_event is used to check if we just saw a tempo/timesig token to know if we should ignore its second occurrence.\n",
        "    previous_event = None\n",
        "    \n",
        "    # Iterate over all midi events, sorted by offset (ascending)\n",
        "    # and handle which tokens will be added to list of tokens\n",
        "    for midi_event in midi_file.flat.elements:\n",
        "        \n",
        "        current_offset = midi_event.offset\n",
        "        \n",
        "        # At the end of the current loop, tokens in this list will be added to the final tokens list\n",
        "        tokens_to_add = list()\n",
        "        \n",
        "        # Check if there are notes that should have ended between the last and current offset (included) \n",
        "        if len(notes_to_stop) != 0:\n",
        "            for note_to_stop, when_to_stop in [note[:] for note in notes_to_stop]:\n",
        "                if when_to_stop <= current_offset:\n",
        "                    time_since_prev_offset = common.opFrac(when_to_stop - previous_offset)\n",
        "                    if time_since_prev_offset > 0:\n",
        "                        tokens_to_add.append(\"wait:\" + str(time_since_prev_offset))\n",
        "                        previous_offset = when_to_stop\n",
        "                    tokens_to_add.append(\"stop_note:\" + note_to_stop)\n",
        "                    notes_to_stop.remove([note_to_stop, when_to_stop])\n",
        "        \n",
        "        # If the offset has changed by >0, account for it by adding a waiting token\n",
        "        if (current_offset > previous_offset and isinstance(midi_event, (note.Note, chord.Chord))):\n",
        "            offset_changed = True\n",
        "            offset_change = common.opFrac(current_offset - previous_offset)\n",
        "            tokens_to_add.append(\"wait:\" + str(offset_change))\n",
        "        \n",
        "        if isinstance(midi_event, tempo.MetronomeMark) and not isinstance(previous_event, tempo.MetronomeMark):\n",
        "            tempo_value = midi_event.number\n",
        "            tokens_to_add, current_tempo = tempo_change_handler(current_tempo, tempo_value, tokens_to_add)\n",
        "        \n",
        "        # If the current midi event is a note, add a note token along with its midi pitch number\n",
        "        # And remember when the note needs to be stopped\n",
        "        if isinstance(midi_event, note.Note):\n",
        "            midi_pitch = str(midi_event.pitch.midi)\n",
        "            note_velocity = midi_event.volume.velocity\n",
        "            \n",
        "            tokens_to_add, current_velocity = velocity_change_handler(current_velocity, note_velocity, tokens_to_add)\n",
        "            \n",
        "            token_string = \"note:\" + midi_pitch\n",
        "            \n",
        "            note_end_offset = common.opFrac(current_offset + midi_event.duration.quarterLength)\n",
        "            \n",
        "            tokens_to_add.append(token_string)\n",
        "            notes_to_stop.append([midi_pitch, note_end_offset])\n",
        "        \n",
        "        # If the current midi event is a chord, do the same as before for every note in the chord\n",
        "        if isinstance(midi_event, chord.Chord):\n",
        "            for individual_note in midi_event:\n",
        "                midi_pitch = str(individual_note.pitch.midi)\n",
        "                note_velocity = midi_event.volume.velocity\n",
        "                \n",
        "                tokens_to_add, current_velocity = velocity_change_handler(current_velocity, note_velocity, tokens_to_add)\n",
        "                \n",
        "                token_string = \"note:\" + midi_pitch\n",
        "                \n",
        "                note_end_offset = common.opFrac(current_offset + midi_event.duration.quarterLength)\n",
        "\n",
        "                tokens_to_add.append(token_string)\n",
        "                notes_to_stop.append([midi_pitch, note_end_offset])\n",
        "        \n",
        "        tokens.extend(tokens_to_add)\n",
        "        \n",
        "        # I can't for the life of me remember why offset_changed is required, but it makes everything work. Do not touch, lol.\n",
        "        if offset_changed:\n",
        "            offset_changed = False\n",
        "            previous_offset = current_offset\n",
        "        previous_event = midi_event\n",
        "    \n",
        "    # After iterating through all midi events, it is necessary to check for note stopping events one more time,\n",
        "    # since the last midi event could have been a note starting event\n",
        "    tokens_to_add = list()\n",
        "    if len(notes_to_stop) != 0:\n",
        "        for note_to_stop, when_to_stop in [note[:] for note in notes_to_stop]:\n",
        "            time_since_prev_offset = common.opFrac(when_to_stop - previous_offset)\n",
        "            if time_since_prev_offset > 0:\n",
        "                tokens_to_add.append(\"wait:\" + str(time_since_prev_offset))\n",
        "                previous_offset = when_to_stop\n",
        "            tokens_to_add.append(\"stop_note:\" + note_to_stop)\n",
        "            notes_to_stop.remove([note_to_stop, when_to_stop])\n",
        "    tokens.extend(tokens_to_add)\n",
        "    \n",
        "    return tokens\n",
        "\n",
        "# Function to convert list of text tokens to a Music21 midi stream\n",
        "# Params: a list of tokens\n",
        "def convert_tokens_to_midi(tokens):\n",
        "    \n",
        "    # A midi stream that will hold midi events converted from tokens\n",
        "    midi_stream = stream.Stream()\n",
        "    \n",
        "    # Keeps track of the current token\n",
        "    current_token_index = 0\n",
        "    \n",
        "    # Keeps track of offset\n",
        "    current_offset = 0\n",
        "    \n",
        "    # Keeps track of velocity\n",
        "    current_velocity = 70\n",
        "    \n",
        "    # The converter ignores BOS and EOS tags\n",
        "    tokens = [token for token in tokens if token not in [\"<EOS>\", \"<BOS>\"]]\n",
        "    \n",
        "    for token in tokens:\n",
        "        token_type = token.split(\":\")[0]\n",
        "        token_value = token.split(\":\")[1]\n",
        "        \n",
        "        # Time signatures are unnecessary for playback. Commented out.\n",
        "        if token_type == \"timesignature\":\n",
        "            timesignature_value = token_value\n",
        "            midi_stream.append(meter.TimeSignature(timesignature_value))\n",
        "        \n",
        "        if token_type == \"tempo\":\n",
        "            tempo_value = float(token_value)\n",
        "            midi_stream.append(tempo.MetronomeMark(number=tempo_value))\n",
        "            \n",
        "        if token_type == \"velocity\":\n",
        "            velocity_value = float(token_value)\n",
        "            current_velocity = velocity_value\n",
        "        \n",
        "        # Converting a note-starting token to a midi event, we need to know its duration.\n",
        "        # To find the duration, we look at the following tokens until we find a corresponding stop_note token.\n",
        "        # While searching for the stop_note token, we add up the values of intermediate wait tokens, denoting duration.\n",
        "        # We identify the corresponding stop_note by the note's midi pitch number. \n",
        "        if token_type == \"note\":\n",
        "            note_duration = 0\n",
        "            note_midi_pitch = token_value\n",
        "\n",
        "            for following_token in tokens[current_token_index + 1:]:\n",
        "                following_token_type = following_token.split(\":\")[0]\n",
        "                following_token_value = following_token.split(\":\")[1]\n",
        "                \n",
        "                if following_token_type == \"wait\":\n",
        "                    wait_duration = common.opFrac(Fraction(following_token_value))\n",
        "                    note_duration += common.opFrac(wait_duration)\n",
        "                    \n",
        "                if following_token_type == \"stop_note\":\n",
        "                    stopped_note_pitch = following_token_value\n",
        "                    if (note_midi_pitch == stopped_note_pitch):\n",
        "                        new_note = note.Note(int(note_midi_pitch))  \n",
        "                        new_note.quarterLength = note_duration\n",
        "                        new_note.volume.velocity = current_velocity\n",
        "                        midi_stream.insert(current_offset, new_note)\n",
        "                        break\n",
        "\n",
        "        if token_type == \"wait\":\n",
        "            wait_duration = common.opFrac(Fraction(token_value))\n",
        "            current_offset += common.opFrac(wait_duration)\n",
        "\n",
        "        current_token_index += 1\n",
        "\n",
        "    return midi_stream"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgFNp9IX4gR3"
      },
      "source": [
        "## Data processing MIDI -> tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBUIl2-A4sOc"
      },
      "source": [
        "MM files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_GW-mN74egd"
      },
      "source": [
        "tokens_mm = []\n",
        "for i in range(500):\n",
        "  midi_path = \"/content/gdrive/MyDrive/test/\" + str(i) + \".mid\"\n",
        "  midi_tokens = convert_midi_to_tokens(midi_path)\n",
        "  tokens_mm.append(midi_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfS6d38X-c0H"
      },
      "source": [
        "import pickle\n",
        "pkl_file = open('midi_mm.txt','wb')\n",
        "pickle.dump(tokens_mm,pkl_file)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wWAdwjf_cREb",
        "outputId": "ba4990bc-64e1-4e38-fb91-106222adc737"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('/content/midi_mm.txt') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_820d3ed4-888f-4364-91bf-04db34c2e303\", \"midi_mm.txt\", 100941202)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhXZAEl7GGGn"
      },
      "source": [
        "tokens_sub = []\n",
        "for i in range(50):\n",
        "  midi_path = \"/content/obj_samps/LSTM_objective\"+ str(i) + \".mid\"\n",
        "  midi_tokens = convert_midi_to_tokens(midi_path)\n",
        "  tokens_sub.append(midi_tokens)\n",
        "\n",
        "#import pickle\n",
        "#pkl_file = open('midi_sub.txt','wb')\n",
        "#pickle.dump(tokens_sub,pkl_file)\n",
        "\n",
        "#from google.colab import files\n",
        "#files.download('/content/midi_sub.txt') "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWjBIDxa0tTo"
      },
      "source": [
        "## Loading both of the datasets and buliding our test, validation and training sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QMW16MF1OwK"
      },
      "source": [
        "import pickle\n",
        "filename = 'midi_mm.txt'\n",
        "with open(filename, 'rb') as f:\n",
        "    midis_mm = pickle.load(f)\n",
        "\n",
        "for piece in midis_mm:\n",
        "  piece.insert(0, \"<BOS>\")\n",
        "  piece.append(\"<EOS>\")\n",
        "  piece.insert(0,'markov') # attach the label here as first element"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14WCcMSL-3ZK"
      },
      "source": [
        "500 markov pieces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0Jxg5YS0sY6",
        "outputId": "52ce7fe0-7bef-4766-e830-48e19a1225df"
      },
      "source": [
        "len(midis_mm)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZoRk7_7-07v"
      },
      "source": [
        "midis_orig = []\n",
        "with open(\"/content/training_data.txt\") as file:\n",
        "    for line in file: \n",
        "        elements = line.strip().split(\" \")\n",
        "        elements.insert(0, \"<BOS>\")\n",
        "        elements.append(\"<EOS>\")\n",
        "        elements.insert(0,'classic') # attach the label here as first element\n",
        "        midis_orig.append(elements)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UL9Nloj5AVag"
      },
      "source": [
        "295 classical pieces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kyO4gj0APQ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae01e699-bd92-4103-d35a-ed5df5df70b9"
      },
      "source": [
        "len(midis_orig)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "295"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-q-hn_JCJ3W"
      },
      "source": [
        "Pooling everything together:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdTt_j_WAgCR"
      },
      "source": [
        "everything = []\n",
        "everything.extend(midis_orig)\n",
        "everything.extend(midis_mm)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5AyTJjrAej1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88281309-01f1-4e29-9f83-c2b5be912878"
      },
      "source": [
        "len(everything)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "795"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDOj_YbjJKbd"
      },
      "source": [
        "everything2 = []\n",
        "maxlen=0\n",
        "for piece in everything:\n",
        "  if len(piece)-1 < 10000:\n",
        "    everything2.append(piece)\n",
        "  if len(piece)-1>maxlen and len(piece)-1< 10000:\n",
        "    maxlen = len(piece)-1 #-label"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GrfJTmQaX9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97a89cf9-999d-4371-9f52-d8860a8362ed"
      },
      "source": [
        "maxlen"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9923"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkV6ruy29C8l",
        "outputId": "1e13efca-c425-4d04-f4fb-df22da4a8b13"
      },
      "source": [
        "print(len(everything2))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "541\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t41yxBuMa6dU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9fac0ac-c6f1-4d6a-cbbf-5027645fa8e6"
      },
      "source": [
        "k=0\n",
        "for e in everything2:\n",
        "  if e[0]==\"markov\":\n",
        "    k+=1\n",
        "print(k)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "310\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhTpd0v-NUS5"
      },
      "source": [
        "unique_tokens = set()\n",
        "for i in everything2:\n",
        "  for j in i:\n",
        "    if j not in {\"markov\",\"classic\"}:\n",
        "      unique_tokens.add(j)\n",
        "unique_tokens = list(unique_tokens)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoId8uS1-nhL"
      },
      "source": [
        "token_int_pairings = {token: unique_tokens.index(token)+2 for token in unique_tokens}\n",
        "token_int_pairings['markov'] = 0\n",
        "token_int_pairings['classic'] = 1\n",
        "\n",
        "\n",
        "everything_ints = []\n",
        "for piece in everything2:\n",
        "  piece_list = []\n",
        "  for element in piece:\n",
        "    piece_list.append(token_int_pairings[element])\n",
        "  everything_ints.append(piece_list)\n",
        "\n",
        "# Save dictionary\n",
        "json.dump(dict(token_int_pairings.items()), open(\"./dictionary.json\", 'w'))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiI8g2qROau_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25269383-0f0b-444b-b349-0d786016399b"
      },
      "source": [
        "len(everything_ints)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "541"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8QIySVXCOSJ"
      },
      "source": [
        "We are going to go with 80:10:10 training testing and validation split here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8FlEfoOCNs1"
      },
      "source": [
        "import random\n",
        "random.seed(92040)\n",
        "random.shuffle(everything_ints)\n",
        "train_set = everything_ints[0:433]\n",
        "#train_set = everything_ints[0:318]\n",
        "#train_set = everything_ints[0:636]\n",
        "train_Y = np.array([seq[0] for seq in train_set],dtype = np.uint8)\n",
        "train_X = [seq[1:] for seq in train_set]\n",
        "test_set = everything_ints[433:487]\n",
        "#test_set = everything_ints[318:358]\n",
        "#test_set = everything_ints[636:716]\n",
        "test_Y = np.array([seq[0] for seq in test_set],dtype = np.uint8)\n",
        "test_X = [seq[1:] for seq in test_set]\n",
        "validation_set = everything_ints[487:]\n",
        "#validation_set = everything_ints[358:397]\n",
        "validation_Y = np.array([seq[0] for seq in validation_set],dtype = np.uint8)\n",
        "validation_X = [seq[1:] for seq in validation_set]\n",
        "#validation_set = everything_ints[716:783]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VI-au_n8dh0J"
      },
      "source": [
        "train_Y[0:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDFZ4Jd9Q-1x"
      },
      "source": [
        "import numpy\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import GRU\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import load_model\n",
        "numpy.random.seed(7)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sF1k1LLiQLS9"
      },
      "source": [
        "train_X = sequence.pad_sequences(train_X, maxlen=maxlen)\n",
        "test_X = sequence.pad_sequences(test_X, maxlen=maxlen)\n",
        "validation_X = sequence.pad_sequences(validation_X, maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nrh2poWcGwOp"
      },
      "source": [
        "train_X = np.expand_dims(train_X, axis=-1)\n",
        "test_X = np.expand_dims(test_X, axis=-1)\n",
        "validation_X = np.expand_dims(validation_X, axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdMQSuS7HLyu",
        "outputId": "8c8592d4-4e28-4fbe-92e6-1675ab128e57"
      },
      "source": [
        "train_X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(433, 9923, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-r3xwKyJIrO"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izaU1e4qTBv7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "outputId": "06165cd2-0933-49b7-f105-9782896e535a"
      },
      "source": [
        "model = Sequential()\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(GRU(64,input_shape=(maxlen,1)))\n",
        "model.add(Dropout(0.5))\n",
        "#model.add(Dropout(0.5))\n",
        "#model.add(GRU(64))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',recall_m])\n",
        "model.fit(train_X, train_Y, epochs=64, batch_size=64,validation_data=(validation_X, validation_Y))\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(test_X, test_Y, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "print(\"Recall: %.2f%%\" % (scores[2]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/64\n",
            "7/7 [==============================] - 40s 5s/step - loss: 0.8771 - accuracy: 0.5238 - recall_m: 0.2649 - val_loss: 0.5617 - val_accuracy: 0.6852 - val_recall_m: 0.0000e+00\n",
            "Epoch 2/64\n",
            "7/7 [==============================] - 35s 5s/step - loss: 0.7890 - accuracy: 0.5522 - recall_m: 0.3796 - val_loss: 0.5572 - val_accuracy: 0.8704 - val_recall_m: 0.5882\n",
            "Epoch 3/64\n",
            "7/7 [==============================] - 35s 5s/step - loss: 0.7580 - accuracy: 0.6235 - recall_m: 0.5900 - val_loss: 0.5003 - val_accuracy: 0.8519 - val_recall_m: 0.5294\n",
            "Epoch 4/64\n",
            "7/7 [==============================] - 35s 5s/step - loss: 0.7013 - accuracy: 0.6264 - recall_m: 0.5782 - val_loss: 0.4389 - val_accuracy: 0.8519 - val_recall_m: 0.5294\n",
            "Epoch 5/64\n",
            "7/7 [==============================] - 35s 5s/step - loss: 0.6135 - accuracy: 0.6729 - recall_m: 0.5915 - val_loss: 0.3887 - val_accuracy: 0.8889 - val_recall_m: 0.6471\n",
            "Epoch 6/64\n",
            "7/7 [==============================] - 35s 5s/step - loss: 0.5633 - accuracy: 0.7136 - recall_m: 0.6749 - val_loss: 0.3379 - val_accuracy: 0.9444 - val_recall_m: 0.8235\n",
            "Epoch 7/64\n",
            "7/7 [==============================] - 35s 5s/step - loss: 0.5073 - accuracy: 0.7339 - recall_m: 0.7254 - val_loss: 0.2769 - val_accuracy: 0.9444 - val_recall_m: 0.8235\n",
            "Epoch 8/64\n",
            "7/7 [==============================] - 36s 5s/step - loss: 0.3902 - accuracy: 0.8294 - recall_m: 0.8286 - val_loss: 0.2100 - val_accuracy: 0.9630 - val_recall_m: 0.8824\n",
            "Epoch 9/64\n",
            "7/7 [==============================] - 36s 5s/step - loss: 0.3596 - accuracy: 0.8399 - recall_m: 0.7876 - val_loss: 0.1404 - val_accuracy: 0.9815 - val_recall_m: 0.9412\n",
            "Epoch 10/64\n",
            "7/7 [==============================] - 35s 5s/step - loss: 0.2260 - accuracy: 0.9287 - recall_m: 0.9040 - val_loss: 0.0901 - val_accuracy: 0.9815 - val_recall_m: 0.9412\n",
            "Epoch 11/64\n",
            "7/7 [==============================] - 35s 5s/step - loss: 0.1570 - accuracy: 0.9498 - recall_m: 0.9088 - val_loss: 0.0480 - val_accuracy: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 12/64\n",
            "7/7 [==============================] - 35s 5s/step - loss: 0.0853 - accuracy: 0.9866 - recall_m: 0.9825 - val_loss: 0.0286 - val_accuracy: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 13/64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-a2b12fc7d24c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecall_m\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# Final evaluation of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7j5K1wXQPw3-",
        "outputId": "67ec983c-c502-42ef-e34a-96492aadf176"
      },
      "source": [
        "# Final evaluation of the model\n",
        "scores = model.evaluate(test_X, test_Y, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "print(\"Recall: %.2f%%\" % (scores[2]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 98.15%\n",
            "Recall: 96.67%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5scrZExUpRx",
        "outputId": "c7ca8988-9f91-4c57-f13d-7c8a2584e64b"
      },
      "source": [
        "model.save('/content/model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YdccYXlQxSJ"
      },
      "source": [
        "## Generated file test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj30UHMeHCUY"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzc5amXOOCsD",
        "outputId": "9aecb52b-51e9-4928-8f16-23070229c169"
      },
      "source": [
        "another_strategy = tf.distribute.MirroredStrategy()\n",
        "with another_strategy.scope():\n",
        "  load_options = tf.saved_model.LoadOptions(experimental_io_device='/job:localhost')\n",
        "  loaded = tf.keras.models.load_model('/content/mdel/',custom_objects={'recall_m':recall_m}, options=load_options)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KocgvOScSmI5"
      },
      "source": [
        "all_ints = []\n",
        "token_int_pairings[\"velocity:90\"] = token_int_pairings[\"velocity:70\"]\n",
        "token_int_pairings[\"velocity:50\"] = token_int_pairings[\"velocity:40\"]\n",
        "token_int_pairings[\"tempo:140\"]  = token_int_pairings[\"tempo:160\"]\n",
        "token_int_pairings['tempo:40'] = token_int_pairings['tempo:60']\n",
        "token_int_pairings['tempo:50.0'] = token_int_pairings['tempo:60']\n",
        "for tr in tokens_sub:\n",
        "  tr.insert(0, \"<BOS>\")\n",
        "  tr.append(\"<EOS>\")\n",
        "  midi_ints = [token_int_pairings[element] for element in tr]\n",
        "  all_ints.append(midi_ints)\n",
        "midi_toks_2 = sequence.pad_sequences(all_ints, maxlen=maxlen)\n",
        "midi_ints_3 = np.expand_dims(midi_toks_2, axis=-1)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGq5ijcgUE3f"
      },
      "source": [
        "preds = loaded.predict(midi_ints_3)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiEUyUv9VGsQ"
      },
      "source": [
        "with open('preds.txt', 'w') as f:\n",
        "    for item in preds:\n",
        "        f.write(\"%s\\n\" % item[0])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IO4V0PuSByjE",
        "outputId": "da9040f8-405f-4a22-8571-c54dc653e3bf"
      },
      "source": [
        "preds[0]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.8689609], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yx8G4uXBETT6",
        "outputId": "afdeb050-8fde-4141-e080-c762da94e7a8"
      },
      "source": [
        "np.sum(loaded.predict_classes(midi_ints_3)==1)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    }
  ]
}
